{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## libraries required\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "% matplotlib inline\n",
    "import time\n",
    "import cplex\n",
    "import cvxpy as cp\n",
    "import cvxopt as copt\n",
    "# import pygraphviz as pgv\n",
    "# from nxpd import draw, nxpdParams\n",
    "# nxpdParams['show'] = 'ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MCF_DiGraph:\n",
    "        \n",
    "    \"\"\"\n",
    "    Extend networkx DiGraph class for our stochastic arc cost purposes\n",
    "    \"\"\"\n",
    "    def __init__(self, residual=False):\n",
    "        self.nxg = nx.DiGraph()\n",
    "        self.residual = residual\n",
    "        self.lam = 0\n",
    "        self.initial_flow = []\n",
    "        self.nmcc = []\n",
    "        self.v_star = None\n",
    "        self.pi = None\n",
    "        self.K = None\n",
    "        \n",
    "    def set_lambda(self, lam=0):\n",
    "        self.lam = lam\n",
    "        self.set_weights()\n",
    "    \n",
    "    def get_lambda(self):\n",
    "        return self.lam\n",
    "        \n",
    "    def set_weights(self):\n",
    "        for u, v, e in self.nxg.edges(data=True):\n",
    "            self.nxg[u][v]['weight'] = self.nxg[u][v]['mu'] + self.lam*self.nxg[u][v]['var']\n",
    "    \n",
    "    def find_feasible(self):\n",
    "        _,_,soln = get_xMV(0, self)\n",
    "        i=0\n",
    "        for u,v,e in self.nxg.edges(data=True):\n",
    "            self.nxg[u][v]['flow'] = soln[i]\n",
    "            i += 1\n",
    "            \n",
    "    def find_feasible_flow(self):\n",
    "        \"\"\"Establish a feasible flow\n",
    "        \"\"\"\n",
    "        # solve max flow problem\n",
    "        G_MaxFlow = self.nxg.copy()\n",
    "        G_MaxFlow.add_node('s')\n",
    "        G_MaxFlow.add_node('t')\n",
    "        for i, data in G_MaxFlow.nodes(data=True):\n",
    "            if (i != 's') and (i != 't'):\n",
    "                b_i = G_MaxFlow.node[i]['demand']\n",
    "                if b_i > 0:\n",
    "                    G_MaxFlow.add_edge('s', i, capacity=b_i)\n",
    "                elif b_i < 0:\n",
    "                    G_MaxFlow.add_edge(i, 't', capacity=-b_i)\n",
    "        \n",
    "        cost, flow = nx.maximum_flow(G_MaxFlow, 's', 't')\n",
    "        \n",
    "        # cost, flow = nx.capacity_scaling(self.nxg)\n",
    "        print(\"The minimum cost is:\", cost)\n",
    "\n",
    "        # The data structure of flow is not consistent with dictionary data structure \n",
    "        # needed for printing the flow vector\n",
    "        feasible_flow = {}\n",
    "        for i in self.nxg.nodes(): \n",
    "            for j in flow[i].keys():\n",
    "                if j != 't':\n",
    "                    feasible_flow[i,j] = flow[i][j]\n",
    "        \n",
    "        \n",
    "        self.initial_flow = feasible_flow\n",
    "        return feasible_flow\n",
    "    \n",
    "    def set_flow_attributes(self, feasible_flow):\n",
    "        \"\"\"Set flow variables for the graph\n",
    "        \"\"\"\n",
    "        nx.set_edge_attributes(self.nxg, feasible_flow, 'flow')\n",
    "            \n",
    "    def draw_graph(self):\n",
    "        \"\"\"Visualize the graph.\n",
    "        \"\"\"\n",
    "\n",
    "        pos = nx.spring_layout(self.nxg)\n",
    "\n",
    "        # draw nodes, edges and labels\n",
    "        nx.draw_networkx_nodes(self.nxg, pos, node_size=500, node_color='green', alpha=0.5)\n",
    "        nx.draw_networkx_edges(self.nxg, pos, width=3, alpha=0.5, edge_color='skyblue')\n",
    "        nx.draw_networkx_labels(self.nxg, pos, font_size=12, font_family='sans-serif')\n",
    "\n",
    "        if not self.residual:\n",
    "            # show the current flow on the arcs\n",
    "            edge_labels = nx.get_edge_attributes(self.nxg, 'capacity')\n",
    "        else:\n",
    "            # show r_ij if it's a residual graph\n",
    "            edge_labels = nx.get_edge_attributes(self.nxg, 'r')\n",
    "\n",
    "        nx.draw_networkx_edge_labels(self.nxg, pos, edge_labels=edge_labels)\n",
    "    \n",
    "    def build_res_network(self, demand='demand', capacity='capacity', weight='weight', mu='mu', var='var', \\\n",
    "                               flow='flow', jw=False):\n",
    "        \"\"\"Build a residual network and initialize a zero flow.\n",
    "        \"\"\"\n",
    "        if sum(self.nxg.nodes[u].get(demand, 0) for u in self.nxg) != 0:\n",
    "            raise nx.NetworkXUnfeasible(\"Sum of the demands should be 0.\")\n",
    "\n",
    "        R = MCF_DiGraph(residual=True)\n",
    "        R.nxg.add_nodes_from((u, {'excess': -self.nxg.nodes[u].get(demand, 0),\n",
    "                              'potential': 0}) for u in self.nxg)\n",
    "\n",
    "        inf = float('inf')\n",
    "        # Detect selfloops with infinite capacities and negative weights.\n",
    "        for u, v, e in nx.selfloop_edges(self.nxg, data=True):\n",
    "            if e.get(weight, 0) < 0 and e.get(capacity, inf) == inf:\n",
    "                raise nx.NetworkXUnbounded(\n",
    "                    'Negative cost cycle of infinite capacity found. '\n",
    "                    'Min cost flow may be unbounded below.')\n",
    "\n",
    "        # Extract edges with positive capacities. Self loops excluded.\n",
    "        if self.nxg.is_multigraph():\n",
    "            edge_list = [(u, v, k, e)\n",
    "                         for u, v, k, e in self.nxg.edges(data=True, keys=True)\n",
    "                         if u != v and e.get(capacity, inf) > 0]\n",
    "        else:\n",
    "    #         edge_list = [(u, v, 0, e) for u, v, e in G.edges(data=True)\n",
    "    #                      if u != v and e.get(capacity, inf) > 0]\n",
    "            edge_list = [(u, v, e) for u, v, e in self.nxg.edges(data=True)\n",
    "                         if u != v and e.get(capacity, inf) > 0]\n",
    "        # Simulate infinity with the larger of the sum of absolute node imbalances\n",
    "        # the sum of finite edge capacities or any positive value if both sums are\n",
    "        # zero. This allows the infinite-capacity edges to be distinguished for\n",
    "        # unboundedness detection and directly participate in residual capacity\n",
    "        # calculation.\n",
    "    #     inf = max(sum(abs(R.nodes[u]['excess']) for u in R),\n",
    "    #               2 * sum(e[capacity] for u, v, k, e in edge_list\n",
    "    #                       if capacity in e and e[capacity] != inf)) or 1\n",
    "        inf = max(sum(abs(R.nxg.nodes[u]['excess']) for u in R.nxg), 2 * sum(e[capacity] for u, v, e in edge_list if capacity in e and e[capacity] != inf)) or 1\n",
    "\n",
    "        #  for u, v, k, e in edge_list:\n",
    "        for u, v, e in edge_list:\n",
    "            r_vu = e.get(flow, 0)\n",
    "            r_uv = e.get(capacity, inf) - e.get(flow, 0)\n",
    "\n",
    "            mu_val = e.get(mu, 0)\n",
    "            var_val = e.get(var, 0)\n",
    "            flow_val = e.get(flow, 0)\n",
    "            cap_val = e.get(capacity, 0)\n",
    "            weight_val = mu_val + self.lam * var_val\n",
    "\n",
    "\n",
    "            # Add both (u, v) and (v, u) into the residual network marked with the\n",
    "            # original key. (key[1] == True) indicates the (u, v) is in the\n",
    "            # original network.\n",
    "\n",
    "\n",
    "            if not jw:\n",
    "                if r_uv != 0:\n",
    "#                     R.add_edge(u, v, key=(k, True), capacity=r_uv, mu=mu, var=var)\n",
    "                    R.nxg.add_edge(u, v, weight=weight_val, capacity=cap_val, mu=mu_val, var=var_val, r=r_uv)\n",
    "\n",
    "                if r_vu != 0:\n",
    "#                     R.add_edge(v, u, key=(k, False), capacity=r_vu, mu=-mu, var=-var)\n",
    "                    R.nxg.add_edge(v, u, weight=-weight_val, capacity=cap_val, mu=-mu_val, var=-var_val, r=r_vu)\n",
    "            else:\n",
    "                if r_uv != 0:\n",
    "                    R.nxg.add_edge(u, v, r=r_uv, weight=weight_val)\n",
    "                if r_vu != 0:\n",
    "                    R.nxg.add_edge(v, u, r=r_vu, weight=-weight_val)\n",
    "\n",
    "        # Record the value simulating infinity.\n",
    "        R.nxg.graph['inf'] = inf\n",
    "\n",
    "        return R\n",
    "\n",
    "    def nmcc_exists(self, G):\n",
    "        \"\"\"Temporary solution\n",
    "        \"\"\"\n",
    "        tol = 1e-10\n",
    "        valid = []\n",
    "        for c in nx.simple_cycles(self.nxg):\n",
    "            if len(c) == 2:\n",
    "                pass\n",
    "            else:\n",
    "                c.append(c[0])\n",
    "                valid.append(c)\n",
    "        \n",
    "        if len(valid) == 0:\n",
    "            return False\n",
    "        else:\n",
    "            \n",
    "            path_cost = []        \n",
    "            for c in valid:\n",
    "                cost = 0\n",
    "                for i in range(len(c)-1):\n",
    "                    u = c[i]\n",
    "                    v = c[i+1]\n",
    "                    try:\n",
    "                        cost += self.nxg[u][v]['mu'] + 2*G.lam*G.nxg[u][v]['flow']*self.nxg[u][v]['var']\n",
    "                    except:\n",
    "                        cost += self.nxg[u][v]['mu'] + 2*G.lam*G.nxg[v][u]['flow']*self.nxg[u][v]['var']\n",
    "                path_cost.append(cost)\n",
    "            \n",
    "            if  np.min(path_cost) < 0:\n",
    "                W = valid[np.argmin(path_cost)]\n",
    "                self.nmcc_cost = np.min(path_cost)\n",
    "                self.nmcc = W\n",
    "                \n",
    "                delta = self.find_delta()\n",
    "                if delta <= 0:\n",
    "                    return False\n",
    "                \n",
    "#                 print('nmcc_cost: ', self.nmcc_cost)\n",
    "                if abs(self.nmcc_cost) < tol:\n",
    "                    self.nmcc_cost = 0.0\n",
    "                    return False\n",
    "                else:\n",
    "                    return True\n",
    "            else:\n",
    "                return False\n",
    "            \n",
    "    def get_nmcc(self):\n",
    "        return self.nmcc\n",
    "        \n",
    "#     def find_mmc(self):\n",
    "#         \"\"\"Temporary solution till MMC is implemented\n",
    "#         \"\"\"\n",
    "#         valid = []\n",
    "#         for c in nx.simple_cycles(self.nxg):\n",
    "#             if len(c) == 2:\n",
    "#                 pass\n",
    "#             else:\n",
    "#                 c.append(c[0])\n",
    "#                 valid.append(c)\n",
    "\n",
    "#         path_cost = []        \n",
    "#         for c in valid:\n",
    "#             cost = 0\n",
    "#             for i in range(len(c)-1):\n",
    "#                 u = c[i]\n",
    "#                 v = c[i+1]\n",
    "#                 cost += self.nxg[u][v]['weight']\n",
    "#             path_cost.append(cost)\n",
    "\n",
    "#         W = valid[np.argmin(path_cost)]\n",
    "\n",
    "#         self.nmcc = W\n",
    "#         return W\n",
    "    \n",
    "    def find_delta(self):\n",
    "        min_r = np.inf\n",
    "        for i in range(len(self.nmcc)-1):\n",
    "            u = self.nmcc[i]\n",
    "            v = self.nmcc[i+1]\n",
    "            rij = self.nxg[u][v]['r']\n",
    "            min_r = min(min_r, rij)\n",
    "\n",
    "        return min_r\n",
    "    \n",
    "#     def find_uc(self, G):\n",
    "#         mincneg = np.inf\n",
    "#         mincpos = np.inf\n",
    "#         for i in range(len(self.nmcc)-1):\n",
    "#             u = self.nmcc[i]\n",
    "#             v = self.nmcc[i+1]\n",
    "#             try:\n",
    "#                 dummy = G.nxg[u][v]['flow']\n",
    "#                 C = 1\n",
    "#             except:\n",
    "#                 C = -1\n",
    "#             if C==1:\n",
    "#                 mincneg = min(mincneg, G.nxg[u][v]['capacity'] - G.nxg[u][v]['flow'])\n",
    "#             else:\n",
    "#                 mincpos = min(mincpos, G.nxg[v][u]['flow'])    \n",
    "#         return min(mincneg, mincpos)\n",
    "\n",
    "    def find_xsi_star(self, G):\n",
    "        nominator = 0\n",
    "        denominator = 0\n",
    "        for i in range(len(self.nmcc)-1):\n",
    "            u = self.nmcc[i]\n",
    "            v = self.nmcc[i+1]\n",
    "            \n",
    "            e = (u, v)\n",
    "            flow = G.nxg[u][v]['flow'] if G.nxg.has_edge(*e) else G.nxg[v][u]['flow']\n",
    "\n",
    "            nominator -= self.nxg[u][v]['mu'] + 2*G.lam*flow*self.nxg[u][v]['var']\n",
    "            denominator += 2*G.lam*abs(self.nxg[u][v]['var'])\n",
    "\n",
    "        return nominator/denominator\n",
    "\n",
    "    def remove_no_r(self,u, v):\n",
    "        if self.nxg[u][v]['r'] == 0:\n",
    "            self.nxg.remove_edge(u,v)\n",
    "\n",
    "    def augment_flow(self, min_r):\n",
    "        for i in range(len(self.nmcc)-1):\n",
    "            u = self.nmcc[i]\n",
    "            v = self.nmcc[i+1]\n",
    "            \n",
    "            weight = self.nxg[u][v]['weight']\n",
    "            mu = self.nxg[u][v]['mu']\n",
    "            var = self.nxg[u][v]['var']\n",
    "    \n",
    "            if self.nxg.has_edge(u, v):\n",
    "                self.nxg[u][v]['r'] -= min_r\n",
    "                \n",
    "            self.remove_no_r(u, v)\n",
    "\n",
    "            if self.nxg.has_edge(v, u):\n",
    "                self.nxg[v][u]['r'] += min_r\n",
    "            else:\n",
    "                self.nxg.add_edge(v, u, r=min_r, weight=-weight, mu=-mu, var=-var)\n",
    "\n",
    "            self.remove_no_r(v, u)\n",
    "\n",
    "    def adjust_flow(self, nmcc, delta):\n",
    "\n",
    "        for i in range(len(nmcc)-1):\n",
    "            u = nmcc[i]\n",
    "            v = nmcc[i+1]\n",
    "\n",
    "            if self.nxg.has_edge(u, v):          \n",
    "                self.nxg[u][v]['flow'] += delta\n",
    "            else:\n",
    "                self.nxg[v][u]['flow'] -= delta\n",
    "    \n",
    "    def mu_cost(self):\n",
    "        cost = 0\n",
    "        for u,v,e in self.nxg.edges(data=True):\n",
    "            cost += e.get('flow', 0) * e.get('mu', 0)\n",
    "            \n",
    "        return cost\n",
    "\n",
    "    def var_cost(self):\n",
    "        \n",
    "        cost = 0\n",
    "        for u,v,e in self.nxg.edges(data=True):\n",
    "            cost += np.square(e.get('flow', 0)) * e.get('var', 0)\n",
    "            \n",
    "        return cost\n",
    "    \n",
    "    def xi_cost(self):\n",
    "\n",
    "        cost = 0\n",
    "        sum_xi = 0\n",
    "        sum_x = 0\n",
    "        for u,v,e in self.nxg.edges(data=True):\n",
    "            cost += e.get('xi', 0) * e.get('var', 0) * e.get('flow', 0)\n",
    "            sum_xi += e.get('xi', 0)\n",
    "            sum_x += e.get('flow', 0)\n",
    "        return cost\n",
    "    def tot_cost(self):\n",
    "\n",
    "        cost = 0\n",
    "        for u,v,e in self.nxg.edges(data=True):\n",
    "            cost += e.get('flow', 0) * e.get('mu', 0) + self.lam*np.square(e.get('flow', 0)) * e.get('var', 0)\n",
    "\n",
    "        return cost\n",
    "    \n",
    "#     def FindSource(self):\n",
    "#     ## WIP\n",
    "#         return 1\n",
    "    \n",
    "#     def nmcc_exists(self, G):\n",
    "#         ## Head\n",
    "#         g = self.nxg\n",
    "#         my_inf = np.inf\n",
    "#         n = len(g.nodes())\n",
    "#         m = len(g.edges())\n",
    "#         d_kv = np.ones((n+1, n))\n",
    "#         d_kv = +my_inf * d_kv\n",
    "#         pi = np.zeros((n+1, n))\n",
    "#         Visit = np.ones((n+1, n))\n",
    "#         M = np.zeros(n)\n",
    "#         K = np.zeros(n)\n",
    "#         v_star = None\n",
    "\n",
    "#         for v in g.nodes():\n",
    "#             Visit[v-1, 0] = False\n",
    "#             Visit[v-1, 1] = False\n",
    "\n",
    "#         s = self.FindSource()\n",
    "#         d_kv[0, s-1] = 0\n",
    "\n",
    "#         pi[0, s-1] = None\n",
    "#         turn = 0\n",
    "#         Visit[s-1, turn] = True\n",
    "\n",
    "#         ## Body\n",
    "#         for k in range(n):\n",
    "#             for v in g.nodes():\n",
    "#                 if Visit[v-1, turn] == True:\n",
    "#                     Visit[v-1, turn] = False\n",
    "#                     for u in g.neighbors(v):\n",
    "                        \n",
    "# #                         try:\n",
    "# #                             w_vu = g[v][u]['mu'] + 2*G.lam*G.nxg[v][u]['flow']*g[v][u]['var']\n",
    "# #                         except:\n",
    "# #                             w_vu = g[v][u]['mu'] + 2*G.lam*G.nxg[u][v]['flow']*g[v][u]['var']\n",
    "                                \n",
    "#                         w_vu = g[v][u]['weight']\n",
    "                        \n",
    "#                         if d_kv[k+1, u-1] > d_kv[k, v-1] + w_vu:\n",
    "#                             d_kv[k+1, u-1] = d_kv[k, v-1] + w_vu\n",
    "#                             pi[k+1, u-1] = v\n",
    "#                             Visit[u-1, 1-turn] = True\n",
    "#             turn = 1 - turn\n",
    "\n",
    "#         ## Tail\n",
    "#         lam = +my_inf\n",
    "#         for v in g.nodes():\n",
    "#             if Visit[v-1, turn] == True:\n",
    "#                 M[v-1] = -my_inf \n",
    "#                 for k in range(n):\n",
    "#                     if M[v-1] < (d_kv[n, v-1] - d_kv[k, v-1])/(n-k): \n",
    "#                         M[v-1] = (d_kv[n, v-1] - d_kv[k, v-1])/(n-k)  \n",
    "#                         K[v-1] = k\n",
    "\n",
    "#                 if lam > M[v-1]: \n",
    "#                     lam = M[v-1] \n",
    "#                     v_star = v\n",
    "        \n",
    "#         self.K = K\n",
    "#         self.v_star = v\n",
    "#         self.pi = pi\n",
    "        \n",
    "#         self.set_nmcc()\n",
    "                    \n",
    "#         return True if lam < 0 else False\n",
    "\n",
    "\n",
    "#     def set_nmcc(self):\n",
    "          \n",
    "#         cycle_len = int(len(self.nxg.nodes()) - self.K[self.v_star - 1])\n",
    "#         self.nmcc = []\n",
    "#         next_v = self.v_star\n",
    "        \n",
    "#         for i in range(cycle_len, 0, -1):\n",
    "#             self.nmcc.append(int(self.pi[i,next_v-1]))\n",
    "#             next_v = int(self.pi[i,next_v-1])\n",
    "\n",
    "#         first = [self.nmcc[-1]]\n",
    "#         self.nmcc = first + self.nmcc\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_toy_problem(lam):\n",
    "\n",
    "    # Toy problem generation (With Stochastic Arc Costs) \\\n",
    "    # This creates the graph on pg 318 (Network Flows by Ahuja)\n",
    "\n",
    "    GAstoch = MCF_DiGraph()\n",
    "    \n",
    "    GAstoch.nxg.add_edge(1,2, weight=1,mu=2,var=3,flow=3,capacity=10)\n",
    "    GAstoch.nxg.add_edge(1,3, weight=10,mu=2,var=3,flow=3,capacity=10)\n",
    "    GAstoch.nxg.add_edge(4,2, weight=0,mu=2,var=3,flow=3,capacity=10)\n",
    "    GAstoch.nxg.add_edge(2,3, weight=3,mu=2,var=3,flow=3,capacity=10)\n",
    "    GAstoch.nxg.add_edge(3,4, weight=2,mu=2,var=3,flow=3,capacity=10)\n",
    "    GAstoch.nxg.add_edge(4,1, weight=8,mu=2,var=3,flow=3,capacity=10)\n",
    "    \n",
    "    GAstoch.nxg.node[1]['demand'] = 1\n",
    "    GAstoch.nxg.node[2]['demand'] = 0\n",
    "    GAstoch.nxg.node[3]['demand'] = 0\n",
    "    GAstoch.nxg.node[4]['demand'] = -1\n",
    "\n",
    "    GAstoch.nxg.node[1]['pos'] = (0,0)\n",
    "    GAstoch.nxg.node[2]['pos'] = (3,3)\n",
    "    GAstoch.nxg.node[3]['pos'] = (3,-3)\n",
    "    GAstoch.nxg.node[4]['pos'] = (6,0)\n",
    "\n",
    "    # Lets assign it to another to keep the original\n",
    "    G = GAstoch\n",
    "    \n",
    "    # Set the lambda parameter for mean-variance tradeoff\n",
    "    G.set_lambda(lam=lam)\n",
    "    \n",
    "    # feasible flow x in the network to start with\n",
    "    initial_flow = G.find_feasible_flow()\n",
    "    \n",
    "#     print('feasible_flow: ', initial_flow )\n",
    "\n",
    "    # set the flow attributes in the graph class\n",
    "    G.set_flow_attributes(initial_flow)\n",
    "\n",
    "    return G\n",
    "\n",
    "def create_random_graph(d_top=10, mu_top=5, var_top=15, num_nodes=5, seed=0):\n",
    "    \"\"\" *** WIP *** \n",
    "    Generates random graph with the given network parameters\n",
    "    \"\"\"\n",
    "    ## Build a dataframe with your connections\n",
    "    # df = pd.DataFrame({ 'from':['A', 'B', 'C','A'], 'to':['D', 'A', 'E','C']})\n",
    "    # df\n",
    "    # Build your graph\n",
    "    # G=nx.from_pandas_dataframe(df, 'from', 'to')\n",
    "\n",
    "    #Need to make it strongly connected - can always do it adding arcs with very large cost. (MMCC) algo requires!\n",
    "    #use something like if nx.is_strongly_connected(G5): to check\n",
    "    #More about generation - satisfy assumptions, guarantee feasibility\n",
    "\n",
    "\n",
    "    #fix random seed for reproducibility\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # create Directed Graph objec\n",
    "    G = MCF_DiGraph()\n",
    "\n",
    "    # number of nodes in the graph\n",
    "    nodes = np.arange(num_nodes) + 1\n",
    "\n",
    "    # create an arch between i and i+1, to ensure connectivity and assign max capacity to these arcs to ensure\n",
    "    # that a feasible flow exists\n",
    "    for node in nodes:\n",
    "        if node != len(nodes):\n",
    "            G.nxg.add_edge(node, node + 1, capacity=d_top, mu=mu_top, var=var_top)\n",
    "    max_node = len(nodes)\n",
    "\n",
    "    # print(np.array(list(dict(G.nxg.out_degree(nodes)).values())).mean())\n",
    "    \n",
    "    # add additional arcs, and assign capacity, mean, variance - by sampling from a U[0, max_param_value]\n",
    "    while np.array(list(dict(G.nxg.out_degree(nodes)).values())).mean() < 1.5:\n",
    "        d = round(np.random.uniform(0,d_top), 2)\n",
    "        mu = round(np.random.uniform(0, mu_top), 2)\n",
    "        var = round(np.random.uniform(0, var_top), 2)\n",
    "        var = round(np.random.normal(var_top, 5, 1)[0],2)\n",
    "        src = np.random.randint(1, max_node)\n",
    "        dest = np.random.randint(src+1, max_node+1)\n",
    "        if not G.nxg.has_edge(src, dest):\n",
    "            G.nxg.add_edge(src, dest, capacity=d, mu=mu, var=var)\n",
    "\n",
    "    #print(np.array(list(dict(G.nxg.out_degree(nodes)).values())).mean())\n",
    "    \n",
    "    # set supply demand at the nodes\n",
    "    G.nxg.node[1]['demand'] = d_top\n",
    "    G.nxg.node[len(nodes)]['demand'] = -d_top\n",
    "    for i in range(2, len(nodes)):\n",
    "        G.nxg.node[i]['demand'] = 0\n",
    "    \n",
    "    # Set the lambda parameter for mean-variance tradeoff\n",
    "    G.set_lambda(lam=0.0)\n",
    "    \n",
    "    # feasible flow x in the network to start with\n",
    "#     initial_flow = G.find_feasible_flow()\n",
    "#     print('feasible_flow: ', initial_flow )\n",
    "\n",
    "    # set the flow attributes in the graph class\n",
    "#     G.set_flow_attributes(initial_flow)\n",
    "    G.find_feasible()\n",
    "    \n",
    "    return G\n",
    "\n",
    "\n",
    "def create_test_instance():\n",
    "    # Toy problem generation (With Stochastic Arc Costs) \\\n",
    "    # This creates the graph on pg 318 (Network Flows by Ahuja)\n",
    "\n",
    "    GAstoch = MCF_DiGraph()\n",
    "    GAstoch.nxg.add_edge(1,2, mu=0, var=0, capacity=10)\n",
    "    GAstoch.nxg.add_edge(1,3, mu=1, var=1, capacity=10)\n",
    "    GAstoch.nxg.add_edge(2,3, mu=5, var=5, capacity=10)\n",
    "    GAstoch.nxg.node[1]['demand'] = 4\n",
    "    GAstoch.nxg.node[2]['demand'] = 0\n",
    "    GAstoch.nxg.node[3]['demand'] = -4\n",
    "\n",
    "    GAstoch.nxg.node[1]['pos'] = (0,0)\n",
    "    GAstoch.nxg.node[2]['pos'] = (3,3)\n",
    "    GAstoch.nxg.node[3]['pos'] = (3,-3)\n",
    "\n",
    "    # Lets assign it to another to keep the original\n",
    "    G = GAstoch\n",
    "    \n",
    "    # Set the lambda parameter for mean-variance tradeoff\n",
    "    G.set_lambda(lam=1)\n",
    "    \n",
    "    # feasible flow x in the network to start with\n",
    "    initial_flow = G.find_feasible_flow()\n",
    "    print('feasible_flow: ', initial_flow )\n",
    "\n",
    "    # set the flow attributes in the graph class\n",
    "    G.set_flow_attributes(initial_flow)\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def solve_mcf_sa(G, R):\n",
    "\n",
    "# while R(x) contains a negative cycle do:\n",
    "#     while nx.negative_edge_cycle(R.nxg):\n",
    "\n",
    "    while R.nmcc_exists(G):\n",
    "#         print('There exists a negative marginal cost cycle')\n",
    "        \n",
    "        \n",
    "        nmcc = R.get_nmcc()\n",
    "#         print('nmcc: ', nmcc)\n",
    "\n",
    "        # find how much to augment\n",
    "        \n",
    "        delta = R.find_delta()\n",
    "#         print('delta: ', delta)\n",
    "        \n",
    "#         delta = R.find_uc(G)\n",
    "#         print('uc: ', delta)\n",
    "    \n",
    "        xsi_star = R.find_xsi_star(G)\n",
    "#         print('xsi_star: ', xsi_star)\n",
    "\n",
    "        augment_amount = min(xsi_star, delta)\n",
    "        \n",
    "        # augment the flow with the min{r_ij: (i,j) element of the cycle W}\n",
    "        R.augment_flow(augment_amount)\n",
    "\n",
    "        # adjust flow (x)\n",
    "        G.adjust_flow(nmcc, augment_amount)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.axis('off')\n",
    "# plt.title('Network')\n",
    "# G.draw_graph()\n",
    "# # print(GA.edges(data=True))\n",
    "# # print(\"Feasible flow dict\", feasible_flow)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.axis('off')\n",
    "# plt.title('Residual Network')\n",
    "# R.draw_graph()\n",
    "# print(R.edges(data=True))\n",
    "f_mid = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_lam:  0.0\n",
      "SOLVED\n",
      "number of iters:  59\n",
      "elapsed time:  0.6931281089782715\n",
      "lambda:  0.003015051751597603\n",
      "177.14564124273656\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Bisection search\n",
    "\n",
    "Given a function f (x) continuous on an interval [a,b] and f (a) * f (b) < 0  \n",
    "Do  \n",
    "       c = (a+b)/2  \n",
    "       if f (a) * f (c) < 0 then  b = c  \n",
    "                             else  a = c  \n",
    "\"\"\"\n",
    "\n",
    "lam_bar = 0.4\n",
    "seed=9\n",
    "num_nodes = 8\n",
    "\n",
    "G = create_random_graph(seed=seed, num_nodes=num_nodes)\n",
    "\n",
    "high = 1.0\n",
    "low = 0.0\n",
    "found = False\n",
    "tol = 1e-20\n",
    "\n",
    "iters = 0\n",
    "\n",
    "start = time.time()\n",
    "while abs(f_mid) > tol:\n",
    "    \n",
    "    mid = (high + low)/2.0\n",
    "    G.set_lambda(lam=mid)\n",
    "    R = G.build_res_network()\n",
    "    solve_mcf_sa(G, R)\n",
    "     \n",
    "    var_lam = G.var_cost()\n",
    "    sigma_lam = np.sqrt(var_lam)\n",
    "    f_mid = mid - lam_bar/(2.0*sigma_lam)\n",
    "    \n",
    "    \n",
    "    G.set_lambda(lam=high)\n",
    "    R = G.build_res_network()\n",
    "    solve_mcf_sa(G, R)\n",
    "     \n",
    "    var_lam = G.var_cost()\n",
    "    sigma_lam = np.sqrt(var_lam)\n",
    "    f_high = high - lam_bar/(2.0*sigma_lam)\n",
    "    \n",
    "    if np.sign(f_mid) == np.sign(f_high):\n",
    "        high = mid\n",
    "    else:\n",
    "        low = mid\n",
    "    iters += 1\n",
    "\n",
    "    \n",
    "print('f_lam: ', f_mid)\n",
    "end = time.time()\n",
    "time_elapsed = end-start\n",
    "\n",
    "print('SOLVED')\n",
    "print('number of iters: ', iters)\n",
    "print('elapsed time: ', time_elapsed)\n",
    "print('lambda: ', mid)\n",
    "\n",
    "lam=mid\n",
    "G.set_lambda(lam=lam)\n",
    "R = G.build_res_network()\n",
    "solve_mcf_sa(G, R)\n",
    "# flow = nx.get_edge_attributes(G.nxg, 'flow')\n",
    "print(lam_bar*np.sqrt(G.var_cost()) + G.mu_cost())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyomo\n",
    "import pandas\n",
    "import pyomo.opt\n",
    "import pyomo.environ as pe\n",
    "from pyomo.environ import Suffix\n",
    "from pyomo.core import Var, Constraint\n",
    "import numpy as np\n",
    "import logging\n",
    "from pyomo.environ import *\n",
    "\n",
    "class MinCostFlow:\n",
    "    \"\"\"This class implements a standard min-cost-flow model.  \n",
    "    It takes as input two csv files, providing data for the nodes and the arcs of the network.  \n",
    "    The nodes file should have columns: Node, Imbalance\n",
    "    that specify the node name and the flow imbalance at the node.  The arcs file should have columns:\n",
    "    Start, End, Cost, UpperBound, LowerBound\n",
    "    that specify an arc start node, an arc end node, a cost for the arc, and upper and lower bounds for the flow.\"\"\"\n",
    "    \n",
    "    def __init__(self, node_data, arc_data, lam=1):\n",
    "        \"\"\"Read in the csv data.\"\"\"\n",
    "        self.node_data = node_data\n",
    "        self.node_data.set_index(['Node'], inplace=True)\n",
    "        self.node_data.sort_index(inplace=True)\n",
    "        \n",
    "        self.arc_data = arc_data\n",
    "        self.arc_data.set_index(['Start','End'], inplace=True)\n",
    "        self.arc_data.sort_index(inplace=True)\n",
    "\n",
    "        self.node_set = self.node_data.index.unique()\n",
    "        self.arc_set = self.arc_data.index.unique()\n",
    "        \n",
    "        neg_dom_data = self.arc_data[self.arc_data['Capacity']==self.arc_data['Flow']]\n",
    "#         pos_dom_data = self.arc_data[self.arc_data['Flow']==0]\n",
    "        eq_zer_data = self.arc_data[self.arc_data['Flow']==0]\n",
    "    \n",
    "        \n",
    "        if len(neg_dom_data > 0):\n",
    "            self.neg_dom_set = neg_dom_data.index.unique()\n",
    "        else:\n",
    "            self.neg_dom_set = []\n",
    "            \n",
    "#         self.pos_dom_set = pos_dom_data.index.unique()\n",
    "        self.eq_zer_set = eq_zer_data.index.unique()\n",
    "#         print(eq_zer_data)\n",
    "    \n",
    "        self.lam = lam\n",
    "        \n",
    "        self.createModel()\n",
    "    \n",
    "    def createModel(self):\n",
    "        \"\"\"Create the pyomo model\"\"\"\n",
    "        self.m = pe.ConcreteModel()\n",
    "\n",
    "        # Create sets\n",
    "        self.m.neg_dom_set = pe.Set(initialize=self.neg_dom_set, dimen=2)\n",
    "#         self.m.pos_dom_set = pe.Set(initialize=self.pos_dom_set, dimen=2)\n",
    "        self.m.eq_zer_set = pe.Set(initialize=self.eq_zer_set, dimen=2)\n",
    "        self.m.node_set = pe.Set(initialize=self.node_set)\n",
    "        self.m.arc_set = pe.Set(initialize=self.arc_set , dimen=2)\n",
    "        \n",
    "        # Create variables\n",
    "        self.m.Y = pe.Var(self.m.arc_set, domain=pe.Reals)\n",
    "        \n",
    "        def flow_eq_cap(m, n1, n2):\n",
    "            e = (n1,n2)\n",
    "#             if self.arc_data.loc[e, 'Flow'] == self.arc_data.loc[e, 'Capacity']:\n",
    "            return m.Y[e] <= 0\n",
    "        \n",
    "#         def flow_eq_zero(m, n1, n2):\n",
    "#             e = (n1,n2)\n",
    "# #             if self.arc_data.loc[e, 'Flow'] == 0:\n",
    "#             return m.Y[e] >= 0\n",
    "\n",
    "        def flow_noflow(m, n1, n2):\n",
    "            e = (n1,n2)\n",
    "            return m.Y[e] == 0\n",
    "            \n",
    "        # Lower bounds rule\n",
    "        def lower_bounds_rule(m, n1, n2):\n",
    "            e = (n1,n2)\n",
    "            return m.Y[e] >= self.arc_data.loc[e, 'LowerBound']\n",
    "\n",
    "        # Upper bounds rule\n",
    "        def upper_bounds_rule(m, n1, n2):\n",
    "            e = (n1,n2)\n",
    "            return m.Y[e] <= self.arc_data.loc[e, 'UpperBound']\n",
    "\n",
    "        # Flow Balance rule\n",
    "        def flow_bal_rule(m, n):\n",
    "            arcs = self.arc_data.reset_index()\n",
    "            preds = arcs[ arcs.End == n ]['Start']\n",
    "            succs = arcs[ arcs.Start == n ]['End']\n",
    "            return sum(m.Y[(p,n)] for p in preds) - sum(m.Y[(n,s)] for s in succs) == self.node_data.loc[n,'Imbalance']\n",
    "\n",
    "        # Objective rule for the mean variance problem\n",
    "        def obj_rule(m):\n",
    "            return sum(self.lam * m.Y[e]**2 * self.arc_data.loc[e, 'Var_Cost'] +\n",
    "                        m.Y[e] * self.arc_data.loc[e, 'Flow']* self.arc_data.loc[e, 'Var_Cost'] for e in self.arc_set)\n",
    "        \n",
    "        self.m.OBJ = pe.Objective(rule=obj_rule, sense=pe.minimize)\n",
    "\n",
    "        self.m.FlowBal = pe.Constraint(self.m.node_set, rule=flow_bal_rule)\n",
    "        self.m.FlowCap = pe.Constraint(self.m.neg_dom_set, rule=flow_eq_cap)\n",
    "#         self.m.FlowZer = pe.Constraint(self.m.pos_dom_set, rule=flow_eq_zero)\n",
    "        self.m.NoFlow = pe.Constraint(self.m.eq_zer_set, rule=flow_noflow)\n",
    "        self.m.UpperBound = pe.Constraint(self.m.arc_set, rule=upper_bounds_rule)\n",
    "        self.m.LowerBound = pe.Constraint(self.m.arc_set, rule=lower_bounds_rule)\n",
    "\n",
    "    def solve(self):\n",
    "        \"\"\"Solve the model.\"\"\"\n",
    "        solver = pyomo.opt.SolverFactory(\"cplex\")\n",
    "        self.m.slack = Suffix(direction=Suffix.IMPORT)\n",
    "        results = solver.solve(self.m, tee=False, keepfiles=False)\n",
    "\n",
    "        self.m.solutions.store_to(results)\n",
    "\n",
    "        \n",
    "        if (results.solver.status != pyomo.opt.SolverStatus.ok):\n",
    "            logging.warning('Check solver not ok?')\n",
    "        if (results.solver.termination_condition != pyomo.opt.TerminationCondition.optimal):  \n",
    "            logging.warning('Check solver optimality?') \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_xi():\n",
    "    arc_data = {'Start':[], 'End':[], 'Flow':[], 'Capacity':[], 'Var_Cost':[], 'LowerBound':[], 'UpperBound':[]}\n",
    "    node_data = {'Node':[], 'Imbalance':[]}\n",
    "    for u, v, e in G.nxg.edges(data=True):\n",
    "        arc_data['Start'].append(u)\n",
    "        arc_data['End'].append(v)\n",
    "        arc_data['Flow'].append(e.get('flow', 0))\n",
    "        arc_data['Capacity'].append(e.get('capacity', 0))\n",
    "        arc_data['Var_Cost'].append(e.get('var', 0))\n",
    "        arc_data['LowerBound'].append(-e.get('flow',0))\n",
    "        arc_data['UpperBound'].append(e.get('capacity',0)-e.get('flow',0))\n",
    "\n",
    "    for u, n in G.nxg.nodes(data=True):\n",
    "\n",
    "        node_data['Node'].append(u)\n",
    "        node_data['Imbalance'].append(0)\n",
    "\n",
    "    arc_df = pandas.DataFrame(data=arc_data)\n",
    "    node_df = pandas.DataFrame(data=node_data)\n",
    "    sp = MinCostFlow(node_df, arc_df, lam=lam) \n",
    "    results = sp.solve()\n",
    "    sp.m.solutions.load_from(results)\n",
    "\n",
    "\n",
    "    for u, v, e in G.nxg.edges(data=True):\n",
    "        link = (u,v)\n",
    "        G.nxg[u][v]['xi'] = sp.m.Y[link].value\n",
    "#         print('edge: %s, flow: %f' % (link, sp.m.Y[link].value))\n",
    "#         print('edge: %s, xi: %f' % (link, G.nxg[u][v]['xi']))\n",
    "#         print('edge: %s, flow: %f' % (link, G.nxg[u][v]['flow']))\n",
    "\n",
    "            \n",
    "#     for i in range(len(G.nxg.edges)):\n",
    "#         e = sp.arc_set[i]\n",
    "#         print('edge: %s, flow: %f' % (e, sp.m.Y[e].value))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot infer number of levels from empty list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-84a322259adb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mf_lam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlam\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlam_bar\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_cost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mget_xi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mvar_cost_der\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxi_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-d61af03cb38c>\u001b[0m in \u001b[0;36mget_xi\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0marc_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marc_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mnode_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0msp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinCostFlow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marc_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-de9bb1eff381>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_data, arc_data, lam)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m#         self.pos_dom_set = pos_dom_data.index.unique()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq_zer_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meq_zer_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;31m#         print(eq_zer_data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/research/lib/python3.5/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3629\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3630\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3631\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shallow_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3633\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'drop_duplicates'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_index_doc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/research/lib/python3.5/site-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36m_shallow_copy\u001b[0;34m(self, values, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;31m# discards freq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'freq'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tuples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/research/lib/python3.5/site-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36mfrom_tuples\u001b[0;34m(cls, tuples, sortorder, names)\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cannot infer number of levels from empty list'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot infer number of levels from empty list"
     ]
    }
   ],
   "source": [
    "lam = 0.1\n",
    "lam_bar = 0.4\n",
    "seed=9\n",
    "num_nodes=8\n",
    "G = create_random_graph(seed=seed, num_nodes=num_nodes)\n",
    "# G = create_toy_problem(lam=lam)\n",
    "\n",
    "tol = 1e-20\n",
    "found=False\n",
    "\n",
    "iters = 0\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "while not found:\n",
    "    \n",
    "    G.set_lambda(lam=lam)\n",
    "    R = G.build_res_network()\n",
    "    solve_mcf_sa(G, R)\n",
    "    \n",
    "    var_cost = G.var_cost()\n",
    "    \n",
    "    f_lam = lam - lam_bar/(2*sqrt(var_cost))\n",
    "    \n",
    "    get_xi()\n",
    "    var_cost_der = G.xi_cost()\n",
    "    \n",
    "    f_lam_der = 1 + (lam_bar/2)*(var_cost**(-3/2))*var_cost_der\n",
    "\n",
    "    lam_prev = lam\n",
    "    lam = lam_prev - f_lam/f_lam_der\n",
    "    \n",
    "    diff = lam - lam_prev\n",
    "    iters += 1\n",
    "    if abs(diff) < tol:\n",
    "        found = True\n",
    "        \n",
    "end = time.time()\n",
    "time_elapsed = end - start    \n",
    "print('SOLVED')\n",
    "print('num iters: ', iters)\n",
    "print('time elapsed: ', time_elapsed)\n",
    "print('lambda: ', lam)\n",
    "\n",
    "G.set_lambda(lam=lam)\n",
    "R = G.build_res_network()\n",
    "solve_mcf_sa(G, R)\n",
    "flow = nx.get_edge_attributes(G.nxg, 'flow')\n",
    "print(lam_bar*np.sqrt(G.var_cost()) + G.mu_cost())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyomo\n",
    "import pandas\n",
    "import pyomo.opt\n",
    "import pyomo.environ as pe\n",
    "from pyomo.environ import Suffix\n",
    "from pyomo.core import Var, Constraint\n",
    "import numpy as np\n",
    "import logging\n",
    "from pyomo.environ import *\n",
    "# from pyomo.util.infeasible import log_infeasible_constraints\n",
    "\n",
    "class MinCostFlowMV:\n",
    "    \"\"\"This class implements a standard min-cost-flow model.  \n",
    "    It takes as input two csv files, providing data for the nodes and the arcs of the network.  \n",
    "    The nodes file should have columns: Node, Imbalance\n",
    "    that specify the node name and the flow imbalance at the node.  The arcs file should have columns:\n",
    "    Start, End, Cost, UpperBound, LowerBound\n",
    "    that specify an arc start node, an arc end node, a cost for the arc, and upper and lower bounds for the flow.\"\"\"\n",
    "    \n",
    "    def __init__(self, node_data, arc_data, lam=1):\n",
    "        \"\"\"Read in the csv data.\"\"\"\n",
    "        self.node_data = node_data\n",
    "        self.node_data.set_index(['Node'], inplace=True)\n",
    "        self.node_data.sort_index(inplace=True)\n",
    "        \n",
    "        self.arc_data = arc_data\n",
    "        self.arc_data.set_index(['Start','End'], inplace=True)\n",
    "        self.arc_data.sort_index(inplace=True)\n",
    "        self.arc_set = self.arc_data.index.unique()\n",
    "\n",
    "        self.node_set = self.node_data.index.unique()\n",
    "        \n",
    "\n",
    "        self.lam = lam\n",
    "        self.createModel()\n",
    "    \n",
    "    def createModel(self):\n",
    "        \"\"\"Create the pyomo model\"\"\"\n",
    "        self.m = pe.ConcreteModel()\n",
    "\n",
    "        # Create sets\n",
    "        self.m.node_set = pe.Set(initialize=self.node_set)\n",
    "        self.m.arc_set = pe.Set(initialize=self.arc_set , dimen=2)\n",
    "\n",
    "        # Create variables\n",
    "        self.m.Y = pe.Var(self.m.arc_set, domain=pe.Reals)\n",
    "        self.m.GMO = pe.Var(self.m.arc_set, domain=pe.Reals)\n",
    "            \n",
    "        # Lower bounds rule\n",
    "        def lower_bounds_rule(m, n1, n2):\n",
    "            e = (n1,n2)\n",
    "            return m.Y[e] >= self.arc_data.loc[e, 'LowerBound']\n",
    "\n",
    "        # Upper bounds rule\n",
    "        def upper_bounds_rule(m, n1, n2):\n",
    "            e = (n1,n2)\n",
    "            return m.Y[e] <= self.arc_data.loc[e, 'UpperBound']\n",
    "    \n",
    "#         def new_var_rule(m, n1, n2):\n",
    "#             e = (n1,n2)\n",
    "#             return m.GMO[e] == self.arc_data.loc[e, 'Var_Cost'] * m.Y[e]\n",
    "        # Flow Balance rule\n",
    "        \n",
    "        def flow_bal_rule(m, n):\n",
    "            arcs = self.arc_data.reset_index()\n",
    "            preds = arcs[ arcs.End == n ]['Start']\n",
    "            succs = arcs[ arcs.Start == n ]['End']\n",
    "            return sum(m.Y[(p,n)] for p in preds) - sum(m.Y[(n,s)] for s in succs) ==  - self.node_data.loc[n,'Imbalance']\n",
    "\n",
    "        # Objective rule for the mean variance problem\n",
    "        def obj_rule(m):\n",
    "            return sum(m.Y[e]*self.arc_data.loc[e, 'Mean_Cost']  + \n",
    "                       self.lam*(m.Y[e]**2) * self.arc_data.loc[e, 'Var_Cost']  for e in self.arc_set)\n",
    "        \n",
    "        self.m.OBJ = pe.Objective(rule=obj_rule, sense=pe.minimize)\n",
    "\n",
    "        self.m.FlowBal = pe.Constraint(self.m.node_set, rule=flow_bal_rule)\n",
    "        self.m.UpperBound = pe.Constraint(self.m.arc_set, rule=upper_bounds_rule)\n",
    "        self.m.LowerBound = pe.Constraint(self.m.arc_set, rule=lower_bounds_rule)\n",
    "        \n",
    "    def solve(self):\n",
    "        \"\"\"Solve the model.\"\"\"\n",
    "        solver = pyomo.opt.SolverFactory(\"cplex\")\n",
    "        self.m.slack = Suffix(direction=Suffix.IMPORT)\n",
    "        results = solver.solve(self.m, tee=False, keepfiles=False, symbolic_solver_labels=True)\n",
    "\n",
    "        self.m.solutions.store_to(results)\n",
    "#         log_infeasible_constraints(self.m)\n",
    "        \n",
    "        if (results.solver.status != pyomo.opt.SolverStatus.ok):\n",
    "            logging.warning('Check solver not ok?')\n",
    "        if (results.solver.termination_condition != pyomo.opt.TerminationCondition.optimal):  \n",
    "            logging.warning('Check solver optimality?') \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_xMV(lam, G):\n",
    "    arc_data = {'Start':[], 'End':[], 'Mean_Cost':[], 'Var_Cost':[], 'LowerBound':[], 'UpperBound':[]}\n",
    "    node_data = {'Node':[], 'Imbalance':[]}\n",
    "    for u, v, e in G.nxg.edges(data=True):\n",
    "        arc_data['Start'].append(u)\n",
    "        arc_data['End'].append(v)\n",
    "        arc_data['Mean_Cost'].append(e.get('mu', 0))\n",
    "        arc_data['Var_Cost'].append(e.get('var',0))\n",
    "        arc_data['LowerBound'].append(0)\n",
    "        arc_data['UpperBound'].append(e.get('capacity',0))\n",
    "\n",
    "    \n",
    "    for u, n in G.nxg.nodes(data=True):\n",
    "        node_data['Node'].append(u)\n",
    "        node_data['Imbalance'].append(n.get('demand',0))\n",
    " \n",
    "\n",
    "    arc_df = pandas.DataFrame(data=arc_data)\n",
    "    node_df = pandas.DataFrame(data=node_data)\n",
    "    sp = MinCostFlowMV(node_df, arc_df, lam=lam) \n",
    "    results = sp.solve()\n",
    "    sp.m.solutions.load_from(results)\n",
    "\n",
    "    var_cost = 0\n",
    "    mean_cost = 0\n",
    "    soln = []\n",
    "    for u, v, e in G.nxg.edges(data=True):\n",
    "        link = (u,v)\n",
    "        var_cost += sp.m.Y[link].value**2 * e.get('var',0)\n",
    "        mean_cost += sp.m.Y[link].value * e.get('mu',0)\n",
    "        soln.append(sp.m.Y[link].value)\n",
    "    return var_cost, mean_cost, soln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_random_graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ad7c92d1fb97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnum_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_random_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# G = create_toy_problem(lam=lam)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_random_graph' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Bisection search\n",
    "\"\"\"\n",
    "\n",
    "seed=9\n",
    "lam_bar = 0.4\n",
    "num_nodes = 8\n",
    "\n",
    "G = create_random_graph(seed=seed, num_nodes=num_nodes)\n",
    "# G = create_toy_problem(lam=lam)\n",
    "\n",
    "high = 1\n",
    "low = 0\n",
    "found = False\n",
    "tol = 1e-30\n",
    "\n",
    "iters = 0\n",
    "\n",
    "start = time.time()\n",
    "while f_mid > tol:\n",
    "    \n",
    "    \n",
    "    G.set_lambda(lam=high)\n",
    "    var_lam, _, _ = get_xMV(high, G)\n",
    "     \n",
    "    sigma_lam = np.sqrt(var_lam)\n",
    "    f_high = high - float(lam_bar)/float((2*sigma_lam))\n",
    "\n",
    "    mid = (high+low)/2.0\n",
    "    G.set_lambda(lam=mid)\n",
    "    var_lam, _, _ = get_xMV(mid, G)\n",
    "     \n",
    "    sigma_lam = np.sqrt(var_lam)\n",
    "    f_mid = mid - float(lam_bar)/float((2*sigma_lam))\n",
    "    \n",
    "    if np.sign(f_mid) == np.sign(f_high):\n",
    "        high = mid\n",
    "    else:\n",
    "        low = mid\n",
    "    iters += 1\n",
    "\n",
    "end = time.time()\n",
    "time_elapsed = end-start\n",
    "\n",
    "print('SOLVED')\n",
    "print('number of iters: ', iters)\n",
    "print('elapsed time: ', time_elapsed)\n",
    "print('lambda: ', lam)\n",
    "\n",
    "G.set_lambda(lam=mid)\n",
    "var_lam = get_xMV(mid, G)\n",
    "varcost, meancost, soln = get_xMV(mid, G)\n",
    "print(lam_bar*np.sqrt(varcost)+meancost)\n",
    "print('====')\n",
    "print('soln: ')\n",
    "print(soln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_random_graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e5a24e4f398e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlam_bar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnum_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_random_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_lambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlam_bar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_random_graph' is not defined"
     ]
    }
   ],
   "source": [
    "# Problem data.\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "\n",
    "seed=9\n",
    "lam_bar = 0.4\n",
    "num_nodes = 8\n",
    "G = create_random_graph(seed=seed, num_nodes=num_nodes)\n",
    "G.set_lambda(lam=lam_bar)\n",
    "\n",
    "m = G.nxg.number_of_edges()\n",
    "n = G.nxg.number_of_nodes()\n",
    "        \n",
    "mu = np.zeros(m)\n",
    "sigma = np.zeros(m)\n",
    "cap = np.zeros(m)\n",
    "d = np.zeros(n)\n",
    "F = np.zeros((m,n))\n",
    "x = cp.Variable(m)\n",
    "x_n = cp.Variable(m)\n",
    "\n",
    "i = 0\n",
    "arc_dict = {}\n",
    "for u, v, e in G.nxg.edges(data=True):\n",
    "    mu[i] = e.get('mu',0)\n",
    "    sigma[i] = np.sqrt(e.get('var',0))\n",
    "    cap[i] = e.get('capacity',0)\n",
    "    arc_dict[i] = (u, v)\n",
    "    i += 1\n",
    "\n",
    "print(arc_dict)\n",
    "i = 0\n",
    "for node, dat in G.nxg.nodes(data=True):\n",
    "    d[i] = dat['demand']\n",
    "    i += 1\n",
    "\n",
    "    arc_data = {'Start':[], 'End':[]}\n",
    "for u, v, e in G.nxg.edges(data=True):\n",
    "    arc_data['Start'].append(u)\n",
    "    arc_data['End'].append(v)\n",
    "    \n",
    "constraints = [0 <= x, x <= cap]\n",
    "for k in range(m):\n",
    "    constraints.append(x_n[k] == sigma[k]*x[k])\n",
    "        \n",
    "arc_data = pandas.DataFrame(data=arc_data)\n",
    "\n",
    "arc_data.set_index(['Start','End'], inplace=True)\n",
    "arc_data.sort_index(inplace=True)\n",
    "# self.arc_set = self.arc_data.index.unique()      \n",
    "\n",
    "arcs = arc_data.reset_index()\n",
    "\n",
    "\n",
    "for i in range(n):\n",
    "    preds = []\n",
    "    succs = []\n",
    "    for key, vals in arc_dict.items():\n",
    "        if vals[0] == i+1:\n",
    "            preds.append(key)\n",
    "        if vals[1] == i+1:\n",
    "            succs.append(key)\n",
    "    print(i)\n",
    "    print(\"=====\")\n",
    "    print(preds)\n",
    "    print(succs)\n",
    "    \n",
    "    constraint = sum(x[p] for p in preds) - sum(x[s] for s in succs) ==  d[i]\n",
    "    print(constraint)\n",
    "    constraints.append(constraint)\n",
    "    \n",
    "\n",
    "\n",
    "# Construct the problem.\n",
    "\n",
    "exp_val = mu.T*x\n",
    "objective = cp.Minimize(exp_val + lam_bar*cp.norm(x_n, 2))\n",
    "\n",
    "\n",
    "prob = cp.Problem(objective, constraints)\n",
    "\n",
    "# The optimal objective value is returned by `prob.solve()`.\n",
    "result = prob.solve(solver=cp.MOSEK, verbose=True)\n",
    "print(\"status:\", prob.status)\n",
    "# The optimal value for x is stored in `x.value`.\n",
    "print(x.value)\n",
    "print(objective.value)\n",
    "# The optimal Lagrange multiplier for a constraint is stored in\n",
    "# `constraint.dual_value`.\n",
    "# print(constraints[0].dual_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SCS', 'MOSEK', 'ECOS_BB', 'ECOS', 'CVXOPT', 'OSQP', 'CPLEX']\n"
     ]
    }
   ],
   "source": [
    "import cvxpy as cp\n",
    "print (cp.installed_solvers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [research]",
   "language": "python",
   "name": "Python [research]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
